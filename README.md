# Kill\_LIFE â€” AIâ€‘Native Embedded Project Template

Bienvenue dans **Kill\_LIFE**, un modÃ¨le de dÃ©pÃ´t pensÃ© pour dÃ©velopper des systÃ¨mes embarquÃ©s Ã  lâ€™Ã¨re des agents. Lâ€™objectif est simpleÂ : offrir une structure prÃªte Ã  lâ€™emploi qui combine spÃ©cifications formalisÃ©es, automatisation via agents, gestion multiâ€‘cibles (ESP32/STM32/Linux), et pratiques de sÃ©curitÃ© adaptÃ©es au dÃ©veloppement assistÃ© par IA.

## âœ¨ Inspirations et principes

Ce projet sâ€™inspire de plusieurs initiatives et bonnes pratiquesÂ :

- **GitHub Agentic Workflows**Â : les workflows agentiques de GitHub, qui introduisent une chaÃ®ne de sanitisation de lâ€™input (neutralisation des mentions, filtrage des URLs, limitation de taille) et lâ€™utilisation de *safe outputs* pour limiter les privilÃ¨ges des agents. Ces principes guident notre pipeline dâ€™automatisationã€420659683624566â€ L747-L857ã€‘ã€11582546369719â€ L160-L168ã€‘.
- **Alertes sur lâ€™injection de prompt**Â : des rapports comme celui dâ€™Aikido Security dÃ©taillent comment des contenus dâ€™issues non fiables peuvent dÃ©tourner un agent et recommandent dâ€™Ã©viter dâ€™injecter du texte non filtrÃ© dans les prompts, de restreindre les outils disponibles et de traiter toute sortie de lâ€™agent comme non fiableã€885973626346785â€ L218-L231ã€‘.
- **RÃ©duction du rayon dâ€™explosion**Â : le guide *promptâ€‘injectionâ€‘defenses* rappelle quâ€™il faut concevoir en assumant que les injections ne seront jamais totalement Ã©liminÃ©es. Cela implique de limiter les privilÃ¨ges, de vÃ©rifier et de sanitariser systÃ©matiquement les entrÃ©es et sorties et de sÃ©parer les rÃ´lesã€408877418785616â€ L277-L304ã€‘.
- **Enforcement des labels PR**Â : pour forcer les PR Ã  respecter un flux prÃ©cis, nous nous appuyons sur lâ€™idÃ©e de lâ€™action GitHub *enforceâ€‘prâ€‘labels*, qui permet dâ€™exiger quâ€™une PR contienne certains labels ou dâ€™en bloquer dâ€™autresã€613342446189111â€ L283-L299ã€‘.
- **Licences open source**Â : le code source est sous licence MIT, les fichiers matÃ©riels sous licence **CERN OHL v2** (promouvant la libertÃ© dâ€™utiliser, dâ€™Ã©tudier, de modifier et de partager des conceptions matÃ©riellesã€572981070514051â€ L86-L91ã€‘) et la documentation sous **CCâ€‘BY 4.0**, qui autorise le partage et lâ€™adaptation avec attributionã€335439356583797â€ L59-L75ã€‘.

## ğŸ”§ FonctionnalitÃ©s clÃ©s

- **DÃ©veloppement guidÃ© par la spÃ©cification**Â : Ã©crivez votre spÃ©cification (user stories, contraintes, architecture) dans `specs/`. Câ€™est la source de vÃ©ritÃ©. Des scripts de validation et un schÃ©ma garantissent la cohÃ©rence.
- **Multiâ€‘agents**Â : des prompts prÃ©dÃ©finis pour les rÃ´les PM, Architecte, Firmware, QA, Doc et Hardware (BMAD/AgentOS) orchestrent les Ã©tapes de la conception et de la mise en Å“uvre.
- **Automation L3 avec sÃ©curitÃ© intÃ©grÃ©e**Â : les workflows GitHub Agentic Workflows (Option A) transforment une issue en Pull Request en appliquant une sanitisation stricte et en crÃ©ant la PR via un *safe output*. Un fallback sur `ai:impl` est possible si aucune Ã©tiquette nâ€™est prÃ©sente, mais vous pouvez activer lâ€™option label obligatoire pour renforcer la gouvernance.
- **Sanitisation renforcÃ©e des issues**Â : un script Python Ã©limine balises HTML, blocs de code, URLs externes, mentions et commandes potentiellement dangereuses avant que le texte ne soit injectÃ© dans un prompt (voir `tools/ai/sanitize_issue.py`).
- **ContrÃ´le des Ã©tiquettes**Â : un workflow impose quâ€™une PR contienne au moins un label `ai:*` (`ai:spec`, `ai:plan`, `ai:tasks`, `ai:impl`, `ai:qa`, `ai:docs`). Sans label, la PR est annotÃ©e par dÃ©faut avec `ai:impl` ou rejetÃ©e selon votre politique.
- **ScopeÂ guard par label**Â : chaque label dÃ©termine les dossiers modifiables (par exemple, `ai:spec` autorise `specs/` et `docs/` ; `ai:impl` autorise `firmware/`). Si un fichier en dehors de la liste est modifiÃ©, le gate Ã©choue.
- **Multiâ€‘cibles et firmware portable**Â : le dossier `firmware/` contient des environnements PlatformIO pour ESP32 (ESPâ€‘IDF) et STM32, ainsi que des tests `native` pour valider la logique cÃ´tÃ© hÃ´te. Ajoutez vos cibles personnalisÃ©es dans `firmware/targets/`.
- **Pipeline matÃ©riel**Â : `hardware/` propose des projets KiCad et des scripts pour gÃ©nÃ©rer le schÃ©ma, valider les rÃ¨gles (DRC/ERC) et exporter la nomenclature. Les profils de conformitÃ© (exÂ : `iot_wifi_eu`) sâ€™appuient sur les standards dans `standards/`.
- **OpenClaw en mode observateur**Â : OpenClaw peut appliquer des labels ou laisser des commentaires sanitisÃ©s sur les issues/PR sans jamais Ã©crire dans le code. Son exÃ©cution doit se faire en bac Ã  sable, sans secretsã€57263998884462â€ L355-L419ã€‘.

## ğŸš€ Prise en main rapide

1. **CrÃ©er votre spÃ©cification**Â : copiez/complÃ©tez un modÃ¨le dans `specs/` ou utilisez `python tools/ai/specify_init.py --name votre-feature` pour gÃ©nÃ©rer un squelette.
2. **DÃ©finir votre profil** (prototype ou iot\_wifi\_eu) via `python tools/compliance/use_profile.py`.
3. **DÃ©veloppement firmware**Â : installez PlatformIO (`pip install platformio`), puis :
   ```bash
   cd firmware
   pio run -e esp32s3_idf   # build
   pio test -e native        # tests unitaires hÃ´te
   ```
4. **Lancer un agent**Â : ouvrez une issue et ajoutez lâ€™Ã©tiquette appropriÃ©e (`ai:spec`, `ai:plan`, etc.). Le workflow agentique crÃ©e une PR avec un diff minimal, les tests et un rÃ©sumÃ© humain.
5. **ContrÃ´ler les PR**Â : la CI exÃ©cute des gates (build/tests/validation spec). Un scope guard vÃ©rifie que les modifications respectent le label.
6. **Lire la documentation**Â : les dossiers `docs/` et `standards/` contiennent des guides (setup KiCad, sÃ©curitÃ©, compliance) et des standards versionnÃ©s injectÃ©s par AgentOS.

## ğŸ—‚ Arborescence principale

- `specs/`Â : spÃ©cifications, architectures, plans et tÃ¢ches.
- `standards/`Â : standards globaux (firmware, hardware, tests), profils de conformitÃ©.
- `bmad/`Â : rÃ´les, rituels et gabarits de handoff pour orchestrer les agents.
- `agents/`Â : prompts pour chaque rÃ´le.
- `tools/`Â : scripts AI (sanitisation, prompts), cockpit de gÃ©nÃ©ration, gates et validateurs.
- `firmware/`Â : projet PlatformIO (targets + tests).
- `hardware/`Â : projets KiCad et scripts de gÃ©nÃ©ration.
- `.github/`Â : workflows CI (build/test, scope guard, enforcement labels) et agents markdown (OptionÂ A).
- `openclaw/`Â : configuration et rÃ¨gles pour OpenClaw en mode observateur.
- `licenses/`Â : copies/summaries des licences MIT, CERNÂ OHLÂ v2 et CCÂ BYÂ 4.0.

## ğŸ“„ Licences

Le code source est diffusÃ© sous **MIT**. Les fichiers matÃ©riels (KiCad, mÃ©caniques, BOM) sont sous **CERNÂ OHLÂ v2 Permissive**, encourageant la collaboration et la libertÃ© dâ€™Ã©tudier et partager les designsã€572981070514051â€ L86-L91ã€‘. La documentation et les spÃ©cifications sont sous **Creative Commons BYÂ 4.0**, permettant la rÃ©utilisation et lâ€™adaptation avec attributionã€335439356583797â€ L59-L75ã€‘.

## ğŸ¤ Contribuer

Les contributions sont les bienvenuesÂ ! Vous pouvez proposer de nouveaux profils cibles, amÃ©liorer les scripts de gating ou enrichir les standards. Nâ€™oubliez pas de suivre la politique antiâ€‘injection dÃ©crite dans `docs/security/anti_prompt_injection_policy.md` et dâ€™ajouter des tests avec vos changements.

---

Ce dÃ©pÃ´t vise Ã  offrir un point de dÃ©part moderne pour des projets embarquÃ©s assistÃ©s par IA, en conciliant innovation et sÃ©curitÃ©. Explorez, adaptez et bÃ¢tissez votre prochain projet en toute confianceÂ !